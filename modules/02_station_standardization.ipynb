{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPS Transit Safety Case Competition - Station Standardization\n",
    "## Prompt 2: Master Station List Creation\n",
    "\n",
    "**Objective:** Create a unified master station list by intelligently merging ridership and coordinate data\n",
    "\n",
    "**Key Challenges:**\n",
    "- Station name mismatch: 86% overlap (63/73 matched)\n",
    "- Duplicate stations (Bloor-Yonge, St. George on multiple lines)\n",
    "- Ridership has 74 records, Stations has 73 unique\n",
    "- Need fuzzy matching for name variants (\"St. George\" vs \"ST GEORGE\")\n",
    "\n",
    "**Author:** Data Science Team\n",
    "\n",
    "**Date:** January 24, 2026\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n",
      "Pandas version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import math\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "Output directory: /Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/TPS_CaseComp/outputs\n",
      "Venue proximity threshold: 2.0 km\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Notebook is inside: TPS_CaseComp/modules/\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input files\n",
    "STATIONS_PATH = DATA_DIR / \"subway-stations.csv\"\n",
    "RIDERSHIP_PATH = DATA_DIR / \"ttc-ridership.csv\"\n",
    "\n",
    "# Output files\n",
    "MASTER_STATIONS_PATH = OUTPUT_DIR / \"02_master_station_list.csv\"\n",
    "MATCHING_REPORT_PATH = OUTPUT_DIR / \"02_name_matching_report.txt\"\n",
    "UNMATCHED_STATIONS_PATH = OUTPUT_DIR / \"02_unmatched_stations.csv\"\n",
    "\n",
    "# Venue coordinates (from competition brief and Google Maps)\n",
    "VENUES = {\n",
    "    'BMO_FIELD': {'lat': 43.6332, 'lon': -79.4189, 'name': 'BMO Field (Exhibition Place)'},\n",
    "    'SCOTIABANK_ARENA': {'lat': 43.6435, 'lon': -79.3791, 'name': 'Scotiabank Arena'},\n",
    "    'ROGERS_CENTRE': {'lat': 43.6414, 'lon': -79.3894, 'name': 'Rogers Centre'}\n",
    "}\n",
    "\n",
    "# Proximity threshold (2km as specified)\n",
    "PROXIMITY_THRESHOLD_KM = 2.0\n",
    "\n",
    "# Fuzzy matching threshold\n",
    "FUZZY_MATCH_THRESHOLD = 0.85\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Venue proximity threshold: {PROXIMITY_THRESHOLD_KM} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined\n",
      "\n",
      "✓ Distance calculation test: Union to BMO Field = 3.36 km (expected ~4.7 km)\n"
     ]
    }
   ],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points on Earth.\n",
    "    Returns distance in kilometers.\n",
    "    \n",
    "    Formula: Haversine distance\n",
    "    Accuracy: ~0.5% error (sufficient for our use case)\n",
    "    \"\"\"\n",
    "    # Convert to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    # Earth radius in kilometers\n",
    "    r = 6371\n",
    "    \n",
    "    return c * r\n",
    "\n",
    "def standardize_station_name(name):\n",
    "    \"\"\"\n",
    "    Standardize station names for consistent matching.\n",
    "    \n",
    "    Rules:\n",
    "    1. Convert to uppercase\n",
    "    2. Remove extra spaces\n",
    "    3. Standardize separators (hyphen vs space)\n",
    "    4. Remove periods and apostrophes\n",
    "    5. Handle special cases (St. → SAINT, etc.)\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and uppercase\n",
    "    name = str(name).upper().strip()\n",
    "    \n",
    "    # Remove periods and apostrophes\n",
    "    name = name.replace('.', '').replace(\"'\", '')\n",
    "    \n",
    "    # Standardize \"Saint\" variations\n",
    "    name = re.sub(r'\\bST\\s+', 'ST ', name)  # Ensure single space after ST\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    \n",
    "    # Trim\n",
    "    name = name.strip()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def fuzzy_match_stations(name1, name2):\n",
    "    \"\"\"\n",
    "    Calculate similarity ratio between two station names.\n",
    "    Returns value between 0 and 1 (1 = perfect match).\n",
    "    \n",
    "    Uses SequenceMatcher (similar to Levenshtein distance).\n",
    "    \"\"\"\n",
    "    if pd.isna(name1) or pd.isna(name2):\n",
    "        return 0.0\n",
    "    \n",
    "    name1 = standardize_station_name(name1)\n",
    "    name2 = standardize_station_name(name2)\n",
    "    \n",
    "    return SequenceMatcher(None, name1, name2).ratio()\n",
    "\n",
    "def find_best_match(target_name, candidate_names, threshold=FUZZY_MATCH_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Find the best matching station name from a list of candidates.\n",
    "    \n",
    "    Returns: (best_match, similarity_score) or (None, 0) if no good match\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for candidate in candidate_names:\n",
    "        score = fuzzy_match_stations(target_name, candidate)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = candidate\n",
    "    \n",
    "    if best_score >= threshold:\n",
    "        return best_match, best_score\n",
    "    else:\n",
    "        return None, best_score\n",
    "\n",
    "print(\"✓ Utility functions defined\")\n",
    "\n",
    "# Test haversine distance\n",
    "# Union Station to BMO Field should be ~4.7 km\n",
    "union_lat, union_lon = 43.6452, -79.3806\n",
    "bmo_lat, bmo_lon = 43.6332, -79.4189\n",
    "test_dist = haversine_distance(union_lat, union_lon, bmo_lat, bmo_lon)\n",
    "print(f\"\\n✓ Distance calculation test: Union to BMO Field = {test_dist:.2f} km (expected ~4.7 km)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "✓ Loaded 73 station records\n",
      "✓ Loaded 74 ridership records\n",
      "\n",
      "Station data columns:\n",
      "  Name: features__attributes__PT_NAME\n",
      "  Latitude: features__attributes__LATITUDE\n",
      "  Longitude: features__attributes__LONGITUDE\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load stations data\n",
    "stations_df = pd.read_csv(STATIONS_PATH, encoding='utf-8-sig')\n",
    "print(f\"✓ Loaded {len(stations_df)} station records\")\n",
    "\n",
    "# Load ridership data\n",
    "ridership_df = pd.read_csv(RIDERSHIP_PATH)\n",
    "print(f\"✓ Loaded {len(ridership_df)} ridership records\")\n",
    "\n",
    "# Identify key columns from stations data (they have long prefixes)\n",
    "station_name_col = [col for col in stations_df.columns if 'PT_NAME' in col][0]\n",
    "lat_col = [col for col in stations_df.columns if 'LATITUDE' in col][0]\n",
    "long_col = [col for col in stations_df.columns if 'LONGITUDE' in col][0]\n",
    "\n",
    "print(f\"\\nStation data columns:\")\n",
    "print(f\"  Name: {station_name_col}\")\n",
    "print(f\"  Latitude: {lat_col}\")\n",
    "print(f\"  Longitude: {long_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Stations Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing stations dataset...\n",
      "\n",
      "Stations dataset prepared: 73 records\n",
      "\n",
      "Sample standardized names:\n",
      "  station_name_original station_name_std\n",
      "0              EGLINTON         EGLINTON\n",
      "1            DAVISVILLE       DAVISVILLE\n",
      "2              ST CLAIR         ST CLAIR\n",
      "3            SUMMERHILL       SUMMERHILL\n",
      "4              ROSEDALE         ROSEDALE\n",
      "5           BLOOR-YONGE      BLOOR-YONGE\n",
      "6                WARDEN           WARDEN\n",
      "7                   BAY              BAY\n",
      "8         ST CLAIR WEST    ST CLAIR WEST\n",
      "9             ST GEORGE        ST GEORGE\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing stations dataset...\\n\")\n",
    "\n",
    "# Extract relevant columns\n",
    "stations_clean = stations_df[[station_name_col, lat_col, long_col]].copy()\n",
    "stations_clean.columns = ['station_name_original', 'latitude', 'longitude']\n",
    "\n",
    "# Standardize station names\n",
    "stations_clean['station_name_std'] = stations_clean['station_name_original'].apply(standardize_station_name)\n",
    "\n",
    "# Remove any nulls\n",
    "stations_clean = stations_clean.dropna(subset=['station_name_std', 'latitude', 'longitude'])\n",
    "\n",
    "print(f\"Stations dataset prepared: {len(stations_clean)} records\")\n",
    "print(f\"\\nSample standardized names:\")\n",
    "print(stations_clean[['station_name_original', 'station_name_std']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Ridership Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ridership dataset...\n",
      "\n",
      "Ridership dataset prepared: 74 records\n",
      "\n",
      "Sample standardized names:\n",
      "  station_name_original station_name_std                     line  ridership\n",
      "0           Bloor-Yonge      BLOOR-YONGE  Line 1 Yonge-University     156643\n",
      "1               College          COLLEGE  Line 1 Yonge-University      39137\n",
      "2            Davisville       DAVISVILLE  Line 1 Yonge-University      15903\n",
      "3        Downsview Park   DOWNSVIEW PARK  Line 1 Yonge-University       5618\n",
      "4                Dundas           DUNDAS  Line 1 Yonge-University      72406\n",
      "5                Dupont           DUPONT  Line 1 Yonge-University      11084\n",
      "6              Eglinton         EGLINTON  Line 1 Yonge-University      60814\n",
      "7         Eglinton West    EGLINTON WEST  Line 1 Yonge-University      13982\n",
      "8                 Finch            FINCH  Line 1 Yonge-University      70775\n",
      "9            Finch West       FINCH WEST  Line 1 Yonge-University      18345\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing ridership dataset...\\n\")\n",
    "\n",
    "# Extract relevant columns\n",
    "ridership_clean = ridership_df[['Station', 'Line', 'Average Weekday Boardings']].copy()\n",
    "ridership_clean.columns = ['station_name_original', 'line', 'ridership']\n",
    "\n",
    "# Standardize station names\n",
    "ridership_clean['station_name_std'] = ridership_clean['station_name_original'].apply(standardize_station_name)\n",
    "\n",
    "print(f\"Ridership dataset prepared: {len(ridership_clean)} records\")\n",
    "print(f\"\\nSample standardized names:\")\n",
    "print(ridership_clean[['station_name_original', 'station_name_std', 'line', 'ridership']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handle Multi-Line Stations (Sum Ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling multi-line stations...\n",
      "\n",
      "Stations appearing on multiple lines: 4\n",
      "\n",
      "Multi-line stations (with line breakdown):\n",
      "\n",
      "  BLOOR-YONGE:\n",
      "    - Line 1 Yonge-University: 156,643 boardings\n",
      "    - Line 2 Bloor-Danforth: 121,531 boardings\n",
      "    → TOTAL: 278,174 boardings\n",
      "\n",
      "  SHEPPARD-YONGE:\n",
      "    - Line 1 Yonge-University: 57,501 boardings\n",
      "    - Line 4 Sheppard: 35,327 boardings\n",
      "    → TOTAL: 92,828 boardings\n",
      "\n",
      "  SPADINA:\n",
      "    - Line 1 Yonge-University: 11,479 boardings\n",
      "    - Line 2 Bloor-Danforth: 27,601 boardings\n",
      "    → TOTAL: 39,080 boardings\n",
      "\n",
      "  ST GEORGE:\n",
      "    - Line 1 Yonge-University: 101,128 boardings\n",
      "    - Line 2 Bloor-Danforth: 108,866 boardings\n",
      "    → TOTAL: 209,994 boardings\n",
      "\n",
      "✓ Aggregated ridership: 70 unique stations\n",
      "  (Reduced from 74 line-specific entries)\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling multi-line stations...\\n\")\n",
    "\n",
    "# Identify stations appearing on multiple lines\n",
    "multi_line_stations = ridership_clean['station_name_std'].value_counts()\n",
    "multi_line_stations = multi_line_stations[multi_line_stations > 1]\n",
    "\n",
    "print(f\"Stations appearing on multiple lines: {len(multi_line_stations)}\")\n",
    "if len(multi_line_stations) > 0:\n",
    "    print(\"\\nMulti-line stations (with line breakdown):\")\n",
    "    for station_name in multi_line_stations.index:\n",
    "        station_entries = ridership_clean[ridership_clean['station_name_std'] == station_name]\n",
    "        print(f\"\\n  {station_name}:\")\n",
    "        for _, row in station_entries.iterrows():\n",
    "            print(f\"    - {row['line']}: {row['ridership']:,.0f} boardings\")\n",
    "        total = station_entries['ridership'].sum()\n",
    "        print(f\"    → TOTAL: {total:,.0f} boardings\")\n",
    "\n",
    "# Aggregate ridership by station (sum across lines)\n",
    "ridership_aggregated = ridership_clean.groupby('station_name_std').agg({\n",
    "    'ridership': 'sum',\n",
    "    'line': lambda x: ' & '.join(sorted(set(x)))  # Combine line names\n",
    "}).reset_index()\n",
    "\n",
    "# Keep original name from first occurrence\n",
    "first_names = ridership_clean.groupby('station_name_std')['station_name_original'].first().reset_index()\n",
    "ridership_aggregated = ridership_aggregated.merge(first_names, on='station_name_std')\n",
    "\n",
    "print(f\"\\n✓ Aggregated ridership: {len(ridership_aggregated)} unique stations\")\n",
    "print(f\"  (Reduced from {len(ridership_clean)} line-specific entries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exact Matching (Station Name Join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing exact name matching...\n",
      "\n",
      "Exact Matching Results:\n",
      "  Both datasets (matched): 68\n",
      "  Only in stations.csv: 5\n",
      "  Only in ridership.csv: 2\n",
      "\n",
      "✓ Exact matches: 68 stations\n",
      "⚠️  Unmatched from stations.csv: 5\n",
      "⚠️  Unmatched from ridership.csv: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing exact name matching...\\n\")\n",
    "\n",
    "# Merge on standardized names\n",
    "master_exact = stations_clean.merge(\n",
    "    ridership_aggregated,\n",
    "    on='station_name_std',\n",
    "    how='outer',\n",
    "    suffixes=('_stations', '_ridership'),\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Analyze matching results\n",
    "match_stats = master_exact['_merge'].value_counts()\n",
    "print(\"Exact Matching Results:\")\n",
    "print(f\"  Both datasets (matched): {match_stats.get('both', 0)}\")\n",
    "print(f\"  Only in stations.csv: {match_stats.get('left_only', 0)}\")\n",
    "print(f\"  Only in ridership.csv: {match_stats.get('right_only', 0)}\")\n",
    "\n",
    "# Separate matched and unmatched\n",
    "matched = master_exact[master_exact['_merge'] == 'both'].copy()\n",
    "unmatched_stations = master_exact[master_exact['_merge'] == 'left_only'].copy()\n",
    "unmatched_ridership = master_exact[master_exact['_merge'] == 'right_only'].copy()\n",
    "\n",
    "print(f\"\\n✓ Exact matches: {len(matched)} stations\")\n",
    "print(f\"⚠️  Unmatched from stations.csv: {len(unmatched_stations)}\")\n",
    "print(f\"⚠️  Unmatched from ridership.csv: {len(unmatched_ridership)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fuzzy Matching for Unmatched Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing fuzzy matching for unmatched stations...\n",
      "\n",
      "Unmatched stations to resolve:\n",
      "\n",
      "From ridership.csv (2):\n",
      "  - HIGHWAY 407\n",
      "  - VAUGHAN METROPOLITAN CENTRE\n",
      "\n",
      "From stations.csv (5):\n",
      "  - ELLESMERE\n",
      "  - LAWRENCE EAST\n",
      "  - MCCOWAN\n",
      "  - MIDLAND\n",
      "  - SCARBOROUGH CENTRE\n",
      "\n",
      "================================================================================\n",
      "Attempting fuzzy matching...\n",
      "================================================================================\n",
      "\n",
      "✗ NO MATCH: 'HIGHWAY 407' (best score: 22.22%)\n",
      "\n",
      "✗ NO MATCH: 'VAUGHAN METROPOLITAN CENTRE' (best score: 48.89%)\n",
      "\n",
      "\n",
      "✓ Fuzzy matching complete: 0 additional matches found\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing fuzzy matching for unmatched stations...\\n\")\n",
    "\n",
    "fuzzy_matches = []\n",
    "\n",
    "# For each unmatched ridership station, try to find a match in unmatched stations\n",
    "if len(unmatched_ridership) > 0 and len(unmatched_stations) > 0:\n",
    "    ridership_names = unmatched_ridership['station_name_std'].tolist()\n",
    "    stations_names = unmatched_stations['station_name_std'].tolist()\n",
    "    \n",
    "    print(\"Unmatched stations to resolve:\")\n",
    "    print(f\"\\nFrom ridership.csv ({len(ridership_names)}):\")\n",
    "    for name in ridership_names:\n",
    "        print(f\"  - {name}\")\n",
    "    \n",
    "    print(f\"\\nFrom stations.csv ({len(stations_names)}):\")\n",
    "    for name in stations_names:\n",
    "        print(f\"  - {name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Attempting fuzzy matching...\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for ridership_name in ridership_names:\n",
    "        best_match, score = find_best_match(ridership_name, stations_names)\n",
    "        \n",
    "        if best_match:\n",
    "            print(f\"✓ MATCH FOUND:\")\n",
    "            print(f\"  Ridership: '{ridership_name}'\")\n",
    "            print(f\"  Stations:  '{best_match}'\")\n",
    "            print(f\"  Similarity: {score:.2%}\\n\")\n",
    "            \n",
    "            # Get the full records\n",
    "            ridership_record = unmatched_ridership[unmatched_ridership['station_name_std'] == ridership_name].iloc[0]\n",
    "            station_record = unmatched_stations[unmatched_stations['station_name_std'] == best_match].iloc[0]\n",
    "            \n",
    "            # Merge\n",
    "            fuzzy_matches.append({\n",
    "                'station_name_std': best_match,  # Use stations.csv name as canonical\n",
    "                'station_name_original_stations': station_record['station_name_original'],\n",
    "                'station_name_original_ridership': ridership_record['station_name_original_ridership'],\n",
    "                'latitude': station_record['latitude'],\n",
    "                'longitude': station_record['longitude'],\n",
    "                'ridership': ridership_record['ridership'],\n",
    "                'line': ridership_record['line'],\n",
    "                'match_type': 'fuzzy',\n",
    "                'match_score': score\n",
    "            })\n",
    "        else:\n",
    "            print(f\"✗ NO MATCH: '{ridership_name}' (best score: {score:.2%})\\n\")\n",
    "\n",
    "print(f\"\\n✓ Fuzzy matching complete: {len(fuzzy_matches)} additional matches found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Combine All Matches into Master List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating master station list...\n",
      "\n",
      "⚠️  Adding 5 stations without ridership data:\n",
      "  - ELLESMERE\n",
      "  - LAWRENCE EAST\n",
      "  - MCCOWAN\n",
      "  - MIDLAND\n",
      "  - SCARBOROUGH CENTRE\n",
      "\n",
      "✓ Master list created: 73 stations\n",
      "\n",
      "Breakdown by match type:\n",
      "match_type\n",
      "exact           68\n",
      "no_ridership     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating master station list...\\n\")\n",
    "\n",
    "# Prepare exact matches\n",
    "exact_master = matched[[\n",
    "    'station_name_std',\n",
    "    'station_name_original_stations',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'ridership',\n",
    "    'line'\n",
    "]].copy()\n",
    "exact_master['match_type'] = 'exact'\n",
    "exact_master['match_score'] = 1.0\n",
    "\n",
    "# Combine exact and fuzzy matches\n",
    "if len(fuzzy_matches) > 0:\n",
    "    fuzzy_df = pd.DataFrame(fuzzy_matches)\n",
    "    fuzzy_df = fuzzy_df[[\n",
    "        'station_name_std',\n",
    "        'station_name_original_stations',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'ridership',\n",
    "        'line',\n",
    "        'match_type',\n",
    "        'match_score'\n",
    "    ]]\n",
    "    master_list = pd.concat([exact_master, fuzzy_df], ignore_index=True)\n",
    "else:\n",
    "    master_list = exact_master.copy()\n",
    "\n",
    "# Add stations without ridership data (still need coordinates for spatial analysis)\n",
    "remaining_stations = unmatched_stations[\n",
    "    ~unmatched_stations['station_name_std'].isin(\n",
    "        [m['station_name_std'] for m in fuzzy_matches]\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "if len(remaining_stations) > 0:\n",
    "    print(f\"⚠️  Adding {len(remaining_stations)} stations without ridership data:\")\n",
    "    for _, row in remaining_stations.iterrows():\n",
    "        print(f\"  - {row['station_name_std']}\")\n",
    "    \n",
    "    # FIX: Use the correct column name from unmatched_stations dataframe\n",
    "    remaining_df = remaining_stations[[\n",
    "        'station_name_std',\n",
    "        'station_name_original_stations',  # This column already exists from the merge\n",
    "        'latitude',\n",
    "        'longitude'\n",
    "    ]].copy()\n",
    "    \n",
    "    remaining_df['ridership'] = np.nan\n",
    "    remaining_df['line'] = 'Unknown'\n",
    "    remaining_df['match_type'] = 'no_ridership'\n",
    "    remaining_df['match_score'] = np.nan\n",
    "    \n",
    "    master_list = pd.concat([master_list, remaining_df], ignore_index=True)\n",
    "\n",
    "# Rename final column\n",
    "master_list.rename(columns={\n",
    "    'station_name_std': 'station_name',\n",
    "    'ridership': 'total_ridership'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Master list created: {len(master_list)} stations\")\n",
    "print(f\"\\nBreakdown by match type:\")\n",
    "print(master_list['match_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate Distances to Key Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distances to key venues...\n",
      "\n",
      "✓ Calculated distances to BMO Field (Exhibition Place)\n",
      "  Closest 5 stations:\n",
      "    ST ANDREW: 3.14 km\n",
      "    OSGOODE: 3.23 km\n",
      "    DUFFERIN: 3.28 km\n",
      "    OSSINGTON: 3.30 km\n",
      "    CHRISTIE: 3.44 km\n",
      "\n",
      "✓ Calculated distances to Scotiabank Arena\n",
      "  Closest 5 stations:\n",
      "    UNION: 0.25 km\n",
      "    KING: 0.64 km\n",
      "    ST ANDREW: 0.66 km\n",
      "    QUEEN: 1.00 km\n",
      "    OSGOODE: 1.01 km\n",
      "\n",
      "✓ Calculated distances to Rogers Centre\n",
      "  Closest 5 stations:\n",
      "    ST ANDREW: 0.76 km\n",
      "    UNION: 0.95 km\n",
      "    OSGOODE: 1.06 km\n",
      "    KING: 1.28 km\n",
      "    ST PATRICK: 1.50 km\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating distances to key venues...\\n\")\n",
    "\n",
    "# Calculate distance to each venue\n",
    "for venue_key, venue_info in VENUES.items():\n",
    "    venue_lat = venue_info['lat']\n",
    "    venue_lon = venue_info['lon']\n",
    "    venue_name = venue_info['name']\n",
    "    \n",
    "    column_name = f'distance_to_{venue_key.lower()}'\n",
    "    \n",
    "    # Calculate distance for each station\n",
    "    master_list[column_name] = master_list.apply(\n",
    "        lambda row: haversine_distance(\n",
    "            row['latitude'], \n",
    "            row['longitude'], \n",
    "            venue_lat, \n",
    "            venue_lon\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Calculated distances to {venue_name}\")\n",
    "    \n",
    "    # Show closest stations\n",
    "    closest = master_list.nsmallest(5, column_name)[['station_name', column_name]]\n",
    "    print(f\"  Closest 5 stations:\")\n",
    "    for idx, row in closest.iterrows():\n",
    "        print(f\"    {row['station_name']}: {row[column_name]:.2f} km\")\n",
    "    print()\n",
    "\n",
    "# Rename distance columns to match spec\n",
    "master_list.rename(columns={\n",
    "    'distance_to_bmo_field': 'distance_to_bmo',\n",
    "    'distance_to_scotiabank_arena': 'distance_to_scotiabank',\n",
    "    'distance_to_rogers_centre': 'distance_to_rogers'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Flag Stations Near Venues (Within 2km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagging stations within 2.0 km of venues...\n",
      "\n",
      "✓ Stations near at least one venue: 8\n",
      "\n",
      "Breakdown by venue:\n",
      "  Near BMO Field: 0\n",
      "  Near Scotiabank Arena: 8\n",
      "  Near Rogers Centre: 7\n",
      "\n",
      "Stations near venues (≤2.0 km):\n",
      "station_name  distance_to_bmo  distance_to_scotiabank  distance_to_rogers  is_near_bmo  is_near_scotiabank  is_near_rogers\n",
      "   ST ANDREW           3.1444                  0.6568              0.7553        False                True            True\n",
      "     OSGOODE           3.2336                  1.0143              1.0561        False                True            True\n",
      "  ST PATRICK           3.4569                  1.4490              1.4961        False                True            True\n",
      "       UNION           3.4845                  0.2517              0.9513        False                True            True\n",
      "        KING           3.7708                  0.6370              1.2843        False                True            True\n",
      "       QUEEN           3.9192                  1.0006              1.5295        False                True            True\n",
      "      DUNDAS           4.0260                  1.4282              1.8097        False                True            True\n",
      "     COLLEGE           4.2656                  1.9906              2.2685        False                True           False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Flagging stations within {PROXIMITY_THRESHOLD_KM} km of venues...\\n\")\n",
    "\n",
    "# Flag if station is near ANY venue\n",
    "master_list['is_near_venue'] = (\n",
    "    (master_list['distance_to_bmo'] <= PROXIMITY_THRESHOLD_KM) |\n",
    "    (master_list['distance_to_scotiabank'] <= PROXIMITY_THRESHOLD_KM) |\n",
    "    (master_list['distance_to_rogers'] <= PROXIMITY_THRESHOLD_KM)\n",
    ")\n",
    "\n",
    "# Individual venue flags (for detailed analysis)\n",
    "master_list['is_near_bmo'] = master_list['distance_to_bmo'] <= PROXIMITY_THRESHOLD_KM\n",
    "master_list['is_near_scotiabank'] = master_list['distance_to_scotiabank'] <= PROXIMITY_THRESHOLD_KM\n",
    "master_list['is_near_rogers'] = master_list['distance_to_rogers'] <= PROXIMITY_THRESHOLD_KM\n",
    "\n",
    "# Summary\n",
    "near_venue_count = master_list['is_near_venue'].sum()\n",
    "print(f\"✓ Stations near at least one venue: {near_venue_count}\")\n",
    "\n",
    "print(f\"\\nBreakdown by venue:\")\n",
    "print(f\"  Near BMO Field: {master_list['is_near_bmo'].sum()}\")\n",
    "print(f\"  Near Scotiabank Arena: {master_list['is_near_scotiabank'].sum()}\")\n",
    "print(f\"  Near Rogers Centre: {master_list['is_near_rogers'].sum()}\")\n",
    "\n",
    "# Show stations near venues\n",
    "if near_venue_count > 0:\n",
    "    print(f\"\\nStations near venues (≤{PROXIMITY_THRESHOLD_KM} km):\")\n",
    "    near_stations = master_list[master_list['is_near_venue']].copy()\n",
    "    near_stations_display = near_stations[[\n",
    "        'station_name',\n",
    "        'distance_to_bmo',\n",
    "        'distance_to_scotiabank',\n",
    "        'distance_to_rogers',\n",
    "        'is_near_bmo',\n",
    "        'is_near_scotiabank',\n",
    "        'is_near_rogers'\n",
    "    ]].sort_values('distance_to_bmo')\n",
    "    \n",
    "    print(near_stations_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUALITY CHECKS\n",
      "================================================================================\n",
      "\n",
      "PASSED CHECKS:\n",
      "  ✓ All stations have valid coordinates\n",
      "  ✓ Station count in expected range: 73 (expected 73-75)\n",
      "  ✓ Ridership data coverage: 68/73 (93.2%)\n",
      "  ✓ All stations have distance calculations\n",
      "  ✓ All distances within reasonable range (max: 20.7 km)\n",
      "  ✓ Proximity flags set: 8 stations near venues\n",
      "\n",
      "================================================================================\n",
      "QUALITY ASSESSMENT: ✓✓✓ EXCELLENT\n",
      "Master station list is ready for spatial analysis.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUALITY CHECKS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "issues = []\n",
    "warnings = []\n",
    "passed = []\n",
    "\n",
    "# Check 1: All stations have coordinates\n",
    "missing_coords = master_list[master_list['latitude'].isna() | master_list['longitude'].isna()]\n",
    "if len(missing_coords) == 0:\n",
    "    passed.append(\"✓ All stations have valid coordinates\")\n",
    "else:\n",
    "    issues.append(f\"✗ {len(missing_coords)} stations missing coordinates\")\n",
    "    print(f\"Stations missing coordinates:\")\n",
    "    print(missing_coords[['station_name', 'latitude', 'longitude']])\n",
    "\n",
    "# Check 2: Expected station count\n",
    "expected_min = 73  # From stations.csv\n",
    "expected_max = 75  # Allowing for minor variations\n",
    "actual_count = len(master_list)\n",
    "\n",
    "if expected_min <= actual_count <= expected_max:\n",
    "    passed.append(f\"✓ Station count in expected range: {actual_count} (expected {expected_min}-{expected_max})\")\n",
    "elif actual_count < expected_min:\n",
    "    warnings.append(f\"⚠️  Fewer stations than expected: {actual_count} (expected {expected_min}+)\")\n",
    "else:\n",
    "    warnings.append(f\"⚠️  More stations than expected: {actual_count} (expected {expected_max} max)\")\n",
    "\n",
    "# Check 3: Ridership data coverage\n",
    "with_ridership = master_list['total_ridership'].notna().sum()\n",
    "ridership_pct = with_ridership / len(master_list) * 100\n",
    "\n",
    "if ridership_pct >= 90:\n",
    "    passed.append(f\"✓ Ridership data coverage: {with_ridership}/{len(master_list)} ({ridership_pct:.1f}%)\")\n",
    "elif ridership_pct >= 80:\n",
    "    warnings.append(f\"⚠️  Ridership coverage acceptable but incomplete: {ridership_pct:.1f}%\")\n",
    "else:\n",
    "    issues.append(f\"✗ Poor ridership coverage: {ridership_pct:.1f}%\")\n",
    "\n",
    "# Check 4: Distance calculations\n",
    "missing_distances = master_list[\n",
    "    master_list['distance_to_bmo'].isna() |\n",
    "    master_list['distance_to_scotiabank'].isna() |\n",
    "    master_list['distance_to_rogers'].isna()\n",
    "]\n",
    "\n",
    "if len(missing_distances) == 0:\n",
    "    passed.append(\"✓ All stations have distance calculations\")\n",
    "else:\n",
    "    issues.append(f\"✗ {len(missing_distances)} stations missing distance calculations\")\n",
    "\n",
    "# Check 5: Reasonable distance ranges\n",
    "max_distance = master_list[['distance_to_bmo', 'distance_to_scotiabank', 'distance_to_rogers']].max().max()\n",
    "if max_distance <= 50:  # Toronto is ~40km wide\n",
    "    passed.append(f\"✓ All distances within reasonable range (max: {max_distance:.1f} km)\")\n",
    "else:\n",
    "    warnings.append(f\"⚠️  Some distances seem large (max: {max_distance:.1f} km) - verify coordinates\")\n",
    "\n",
    "# Check 6: Near venue flags\n",
    "if near_venue_count > 0:\n",
    "    passed.append(f\"✓ Proximity flags set: {near_venue_count} stations near venues\")\n",
    "else:\n",
    "    warnings.append(\"⚠️  No stations flagged as near venues (threshold may be too strict)\")\n",
    "\n",
    "# Print results\n",
    "print(\"PASSED CHECKS:\")\n",
    "for item in passed:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "if warnings:\n",
    "    print(f\"\\nWARNINGS:\")\n",
    "    for item in warnings:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "if issues:\n",
    "    print(f\"\\nISSUES:\")\n",
    "    for item in issues:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "# Overall assessment\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "if len(issues) == 0:\n",
    "    status = \"✓✓✓ EXCELLENT\"\n",
    "    message = \"Master station list is ready for spatial analysis.\"\n",
    "elif len(issues) <= 1 and len(warnings) <= 2:\n",
    "    status = \"✓ GOOD\"\n",
    "    message = \"Master station list is acceptable with minor caveats.\"\n",
    "else:\n",
    "    status = \"⚠️  NEEDS REVIEW\"\n",
    "    message = \"Review issues before proceeding.\"\n",
    "\n",
    "print(f\"QUALITY ASSESSMENT: {status}\")\n",
    "print(f\"{message}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing final dataset...\n",
      "\n",
      "✓ Final dataset prepared: 73 stations\n",
      "\n",
      "Column order:\n",
      "  1. station_name\n",
      "  2. latitude\n",
      "  3. longitude\n",
      "  4. total_ridership\n",
      "  5. line\n",
      "  6. distance_to_bmo\n",
      "  7. distance_to_scotiabank\n",
      "  8. distance_to_rogers\n",
      "  9. is_near_venue\n",
      "  10. is_near_bmo\n",
      "  11. is_near_scotiabank\n",
      "  12. is_near_rogers\n",
      "\n",
      "Top 10 stations by ridership:\n",
      "     station_name  total_ridership  \\\n",
      "0     BLOOR-YONGE      278174.0000   \n",
      "1       ST GEORGE      209994.0000   \n",
      "2           UNION      136515.0000   \n",
      "3  SHEPPARD-YONGE       92828.0000   \n",
      "4          DUNDAS       72406.0000   \n",
      "5           FINCH       70775.0000   \n",
      "6        EGLINTON       60814.0000   \n",
      "7         KIPLING       49392.0000   \n",
      "8         KENNEDY       42881.0000   \n",
      "9         COLLEGE       39137.0000   \n",
      "\n",
      "                                              line  \n",
      "0  Line 1 Yonge-University & Line 2 Bloor-Danforth  \n",
      "1  Line 1 Yonge-University & Line 2 Bloor-Danforth  \n",
      "2                          Line 1 Yonge-University  \n",
      "3        Line 1 Yonge-University & Line 4 Sheppard  \n",
      "4                          Line 1 Yonge-University  \n",
      "5                          Line 1 Yonge-University  \n",
      "6                          Line 1 Yonge-University  \n",
      "7                            Line 2 Bloor-Danforth  \n",
      "8                            Line 2 Bloor-Danforth  \n",
      "9                          Line 1 Yonge-University  \n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing final dataset...\\n\")\n",
    "\n",
    "# Select and order columns as specified\n",
    "final_columns = [\n",
    "    'station_name',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'total_ridership',\n",
    "    'line',\n",
    "    'distance_to_bmo',\n",
    "    'distance_to_scotiabank',\n",
    "    'distance_to_rogers',\n",
    "    'is_near_venue',\n",
    "    'is_near_bmo',\n",
    "    'is_near_scotiabank',\n",
    "    'is_near_rogers'\n",
    "]\n",
    "\n",
    "master_final = master_list[final_columns].copy()\n",
    "\n",
    "# Sort by ridership (descending) for easier reference\n",
    "master_final = master_final.sort_values('total_ridership', ascending=False, na_position='last')\n",
    "\n",
    "# Reset index\n",
    "master_final = master_final.reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Final dataset prepared: {len(master_final)} stations\")\n",
    "print(f\"\\nColumn order:\")\n",
    "for i, col in enumerate(master_final.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nTop 10 stations by ridership:\")\n",
    "print(master_final[['station_name', 'total_ridership', 'line']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving outputs...\n",
      "\n",
      "✓ Saved master station list: /Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/TPS_CaseComp/outputs/02_master_station_list.csv\n",
      "  Records: 73\n",
      "  Columns: 12\n",
      "\n",
      "⚠️  Unmatched ridership stations: 2\n",
      "  Saved to: /Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/TPS_CaseComp/outputs/02_unmatched_stations.csv\n",
      "    - HIGHWAY 407\n",
      "    - VAUGHAN METROPOLITAN CENTRE\n",
      "\n",
      "✓ Saved matching report: /Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/TPS_CaseComp/outputs/02_name_matching_report.txt\n",
      "\n",
      "================================================================================\n",
      "PROMPT 2 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving outputs...\\n\")\n",
    "\n",
    "# Save master station list\n",
    "master_final.to_csv(MASTER_STATIONS_PATH, index=False)\n",
    "print(f\"✓ Saved master station list: {MASTER_STATIONS_PATH}\")\n",
    "print(f\"  Records: {len(master_final)}\")\n",
    "print(f\"  Columns: {len(master_final.columns)}\")\n",
    "\n",
    "# Save unmatched stations report (if any)\n",
    "unmatched_remaining = []\n",
    "\n",
    "# Check for remaining unmatched ridership entries\n",
    "ridership_matched_names = set(master_final['station_name'].unique())\n",
    "all_ridership_names = set(ridership_aggregated['station_name_std'].unique())\n",
    "unmatched_ridership_names = all_ridership_names - ridership_matched_names\n",
    "\n",
    "if len(unmatched_ridership_names) > 0:\n",
    "    print(f\"\\n⚠️  Unmatched ridership stations: {len(unmatched_ridership_names)}\")\n",
    "    unmatched_ridership_df = ridership_aggregated[\n",
    "        ridership_aggregated['station_name_std'].isin(unmatched_ridership_names)\n",
    "    ]\n",
    "    unmatched_ridership_df.to_csv(UNMATCHED_STATIONS_PATH, index=False)\n",
    "    print(f\"  Saved to: {UNMATCHED_STATIONS_PATH}\")\n",
    "    for name in sorted(unmatched_ridership_names):\n",
    "        print(f\"    - {name}\")\n",
    "\n",
    "# Generate matching report\n",
    "report_lines = []\n",
    "report_lines.append(\"=\"*80)\n",
    "report_lines.append(\"STATION NAME MATCHING REPORT\")\n",
    "report_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "report_lines.append(\"=\"*80)\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"SUMMARY:\")\n",
    "report_lines.append(f\"  Input - Stations dataset: {len(stations_clean)} records\")\n",
    "report_lines.append(f\"  Input - Ridership dataset: {len(ridership_clean)} records\")\n",
    "report_lines.append(f\"  Input - Unique ridership stations: {len(ridership_aggregated)} (after aggregating multi-line)\")\n",
    "report_lines.append(f\"  Output - Master list: {len(master_final)} stations\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"MATCHING BREAKDOWN:\")\n",
    "report_lines.append(f\"  Exact matches: {(master_list['match_type'] == 'exact').sum()}\")\n",
    "report_lines.append(f\"  Fuzzy matches: {(master_list['match_type'] == 'fuzzy').sum()}\")\n",
    "report_lines.append(f\"  Stations without ridership: {(master_list['match_type'] == 'no_ridership').sum()}\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"FUZZY MATCHES DETAIL:\")\n",
    "if len(fuzzy_matches) > 0:\n",
    "    for match in fuzzy_matches:\n",
    "        report_lines.append(f\"  - Ridership: '{match['station_name_original_ridership']}'\")\n",
    "        report_lines.append(f\"    Stations:  '{match['station_name_original_stations']}'\")\n",
    "        report_lines.append(f\"    Score: {match['match_score']:.2%}\")\n",
    "        report_lines.append(\"\")\n",
    "else:\n",
    "    report_lines.append(\"  (None)\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"VENUE PROXIMITY:\")\n",
    "report_lines.append(f\"  Threshold: {PROXIMITY_THRESHOLD_KM} km\")\n",
    "report_lines.append(f\"  Stations near any venue: {near_venue_count}\")\n",
    "report_lines.append(f\"  Near BMO Field: {master_final['is_near_bmo'].sum()}\")\n",
    "report_lines.append(f\"  Near Scotiabank Arena: {master_final['is_near_scotiabank'].sum()}\")\n",
    "report_lines.append(f\"  Near Rogers Centre: {master_final['is_near_rogers'].sum()}\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"DATA QUALITY:\")\n",
    "report_lines.append(f\"  Stations with coordinates: {master_final['latitude'].notna().sum()}\")\n",
    "report_lines.append(f\"  Stations with ridership: {master_final['total_ridership'].notna().sum()}\")\n",
    "report_lines.append(f\"  Ridership coverage: {master_final['total_ridership'].notna().sum() / len(master_final) * 100:.1f}%\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"TOP 10 STATIONS BY RIDERSHIP:\")\n",
    "for idx, row in master_final.head(10).iterrows():\n",
    "    ridership_str = f\"{row['total_ridership']:,.0f}\" if pd.notna(row['total_ridership']) else \"N/A\"\n",
    "    report_lines.append(f\"  {idx+1}. {row['station_name']}: {ridership_str} boardings/day\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"=\"*80)\n",
    "report_lines.append(\"END OF REPORT\")\n",
    "report_lines.append(\"=\"*80)\n",
    "\n",
    "# Save report\n",
    "with open(MATCHING_REPORT_PATH, 'w') as f:\n",
    "    f.write('\\n'.join(report_lines))\n",
    "\n",
    "print(f\"\\n✓ Saved matching report: {MATCHING_REPORT_PATH}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PROMPT 2 COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL SUMMARY STATISTICS:\n",
      "================================================================================\n",
      "\n",
      "Master Station List:\n",
      "  Total stations: 73\n",
      "  With ridership data: 68\n",
      "  Without ridership data: 5\n",
      "\n",
      "Ridership Statistics:\n",
      "count       68.0000\n",
      "mean     30992.1029\n",
      "std      43591.4799\n",
      "min       3180.0000\n",
      "25%      11641.7500\n",
      "50%      19733.5000\n",
      "75%      31017.5000\n",
      "max     278174.0000\n",
      "Name: total_ridership, dtype: float64\n",
      "\n",
      "Distance Statistics (km):\n",
      "       distance_to_bmo  distance_to_scotiabank  distance_to_rogers\n",
      "count          73.0000                 73.0000             73.0000\n",
      "mean            8.9779                  8.0214              8.0905\n",
      "std             5.1984                  5.1604              5.1792\n",
      "min             3.1444                  0.2517              0.7553\n",
      "25%             4.2804                  3.7982              3.7766\n",
      "50%             7.4537                  7.0493              7.0600\n",
      "75%            13.4475                 12.5064             11.7935\n",
      "max            20.6959                 18.2262             18.5033\n",
      "\n",
      "Venue Proximity Summary:\n",
      "  Stations ≤2.0km from any venue: 8\n",
      "  Stations ≤2.0km from BMO Field: 0\n",
      "  Stations ≤2.0km from Scotiabank: 8\n",
      "  Stations ≤2.0km from Rogers Centre: 7\n",
      "\n",
      "================================================================================\n",
      "Ready for Prompt 3: Spatial Join (Crimes → Stations)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFINAL SUMMARY STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nMaster Station List:\")\n",
    "print(f\"  Total stations: {len(master_final)}\")\n",
    "print(f\"  With ridership data: {master_final['total_ridership'].notna().sum()}\")\n",
    "print(f\"  Without ridership data: {master_final['total_ridership'].isna().sum()}\")\n",
    "\n",
    "print(f\"\\nRidership Statistics:\")\n",
    "print(master_final['total_ridership'].describe())\n",
    "\n",
    "print(f\"\\nDistance Statistics (km):\")\n",
    "distance_stats = master_final[['distance_to_bmo', 'distance_to_scotiabank', 'distance_to_rogers']].describe()\n",
    "print(distance_stats)\n",
    "\n",
    "print(f\"\\nVenue Proximity Summary:\")\n",
    "print(f\"  Stations ≤{PROXIMITY_THRESHOLD_KM}km from any venue: {master_final['is_near_venue'].sum()}\")\n",
    "print(f\"  Stations ≤{PROXIMITY_THRESHOLD_KM}km from BMO Field: {master_final['is_near_bmo'].sum()}\")\n",
    "print(f\"  Stations ≤{PROXIMITY_THRESHOLD_KM}km from Scotiabank: {master_final['is_near_scotiabank'].sum()}\")\n",
    "print(f\"  Stations ≤{PROXIMITY_THRESHOLD_KM}km from Rogers Centre: {master_final['is_near_rogers'].sum()}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Ready for Prompt 3: Spatial Join (Crimes → Stations)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Outputs Summary\n",
    "\n",
    "### Master Station List\n",
    "- **File:** `02_master_station_list.csv`\n",
    "- **Records:** ~73-75 stations (exact vs fuzzy vs no-ridership)\n",
    "- **Columns:** 12 fields including coordinates, ridership, distances, proximity flags\n",
    "\n",
    "### Name Matching\n",
    "- **Exact matches:** Stations where names matched perfectly after standardization\n",
    "- **Fuzzy matches:** Stations matched using similarity algorithm (≥85% threshold)\n",
    "- **Unmatched:** Stations in one dataset but not the other\n",
    "\n",
    "### Venue Proximity\n",
    "- **BMO Field:** Exhibition Place (FIFA 2026 venue)\n",
    "- **Scotiabank Arena:** Major concerts and sports events\n",
    "- **Rogers Centre:** Blue Jays games and concerts\n",
    "- **Threshold:** 2km radius\n",
    "\n",
    "### Next Steps\n",
    "1. Use master station list for spatial join with crime data (Prompt 3)\n",
    "2. Venue proximity flags will identify FIFA-critical stations\n",
    "3. Ridership data will weight risk assessments\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
